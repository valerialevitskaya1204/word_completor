{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"notebookId":"53997d2d-afb8-4477-8874-b6d46299f06c","notebookPath":"seminar.ipynb","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13059568,"sourceType":"datasetVersion","datasetId":8270033}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Глубинное обучение для текстовых данных, ФКН ВШЭ\n\n## Домашнее задание 1: Text Suggestion\n\n__Мягкий дедлайн: 24.10 23:59__   \n__Жесткий дедлайн: 27.10 23:59__\n\n### О задании\n\nВ этом задании вам предстоит реализовать систему, предлагающую удачное продолжение слова или нескольких следующих слов в режиме реального времени по типу тех, которые используются в почте или поисковой строке. За дополнительные баллы полученную систему нужно будет обернуть в пользовательский интерфейс с помощью библиотеки [reflex](https://github.com/reflex-dev/reflex) или аналогов. В этой домашке вам не придется обучать никаких моделей, мы ограничимся n-граммной генерацией.\n\n### Структура\n\nЭто домашнее задание состоит из двух частей: основной и бонусной. В первой вам нужно будет выполнить 5 заданий, по итогам которых вы получите минимально рабочее решение. А во второй, пользуясь тем, что вы уже сделали реализовать полноценную систему подсказки текста с пользовательским интерфейсом. Во второй части мы никак не будем ограничивать вашу фантазию. Делайте что угодно, лишь бы в результате получился удобный фреймворк. Чем лучше у вас будет результат, тем больше баллов вы получите. Если будет совсем хорошо, то мы добавим бонусов сверху по своему усмотрению.\n\n### Оценивание и штрафы\n\nМаксимально допустимая оценка за работу — 15 баллов. Сдавать задание после жесткого дедлайна нельзя. При сдачи решения после мягкого дедлайна за каждый день просрочки снимается по __одному__ баллу.\n\nЗадание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Весь код должен быть написан самостоятельно. Чужим кодом для пользоваться запрещается даже с указанием ссылки на источник. В разумных рамках, конечно. Взять пару очевидных строчек кода для реализации какого-то небольшого функционала можно.\n\nНеэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код.\n\nПри сдаче зададания в anytask вам будет необходимо сдать весь код, а если вы возьметесь за бонусную часть, то еще отчет и видео с демонстрацией вашего UI. За основную часть можно получить до __10-ти__ баллов, а за бонусную – до __5-ти__ баллов.","metadata":{}},{"cell_type":"markdown","source":"### Данные\n\nДля получения текстовых статистик используйте датасет `emails.csv`. Вы можете найти его по [ссылке](https://disk.yandex.ru/d/ikyUhWPlvfXxCg). Он содержит более 500 тысяч электронных писем на английском языке.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nemails = pd.read_csv('/kaggle/input/emails/emails.csv')\nlen(emails)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:31:44.677811Z","iopub.execute_input":"2025-09-23T19:31:44.678074Z","iopub.status.idle":"2025-09-23T19:32:08.597179Z","shell.execute_reply.started":"2025-09-23T19:31:44.678048Z","shell.execute_reply":"2025-09-23T19:32:08.596384Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"517401"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"Заметьте, что данные очень грязные. В каждом письме содержится различная мета-информация, которая будет только мешать при предсказании продолжения текста.\n\n__Задание 1 (2 балла).__ Очистите корпус текстов по вашему усмотрению и объясните свой выбор. В идеале обработанные тексты должны содержать только текст самого письма и ничего лишнего по типу ссылок, адресатов и прочих символов, которыми мы точно не хотим продолжать текст.","metadata":{}},{"cell_type":"code","source":"emails['message'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:32:16.723587Z","iopub.execute_input":"2025-09-23T19:32:16.723831Z","iopub.status.idle":"2025-09-23T19:32:16.732789Z","shell.execute_reply.started":"2025-09-23T19:32:16.723813Z","shell.execute_reply":"2025-09-23T19:32:16.732055Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"\"Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\\nDate: Mon, 14 May 2001 16:39:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: tim.belden@enron.com\\nSubject: \\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: Tim Belden <Tim Belden/Enron@EnronXGate>\\nX-cc: \\nX-bcc: \\nX-Folder: \\\\Phillip_Allen_Jan2002_1\\\\Allen, Phillip K.\\\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nHere is our forecast\\n\\n \""},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"буду чистить по последнему заголовку из метаданных nX-FileName:. надо проверить, что каждое наблюдение в датасете имеет такой заголовок","metadata":{}},{"cell_type":"code","source":"import re\n\ntext = \"aakldslsdldsdls\\nX-FileName: pallen (Non-Privileged).pst.\\n\\nSome Normal Text.\\nlya lya\\n\\n\"\nresult = re.sub(r'(?s).*?X-FileName:[^\\n]*\\.[\\s]*(.*)', r'\\1', text)\nprint(result) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:32:19.717143Z","iopub.execute_input":"2025-09-23T19:32:19.717426Z","iopub.status.idle":"2025-09-23T19:32:19.722337Z","shell.execute_reply.started":"2025-09-23T19:32:19.717404Z","shell.execute_reply":"2025-09-23T19:32:19.721610Z"}},"outputs":[{"name":"stdout","text":"Some Normal Text.\nlya lya\n\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"проверим, что регулярное выражение нормально отрабатавает на всех данных с датасетах","metadata":{}},{"cell_type":"code","source":"# your code here\nimport pandas as pd\nimport re\n\npattern = re.compile(r'(?s).*?X-FileName:[^\\n]*\\.[\\s]*(.*)')\n\ndef process_texts_vect(texts):\n    cleaned_texts = []\n    is_non_empty = []\n    \n    for text in texts:\n        match = pattern.search(text)\n        if match:\n            cleaned = match.group(1)\n        else:\n            cleaned = text\n        cleaned = cleaned.split('\\n', 1)[-1] if '\\n' in cleaned else cleaned\n        cleaned_texts.append(cleaned)\n        is_non_empty.append(1 if cleaned.strip() != '' else 0)\n    \n    return cleaned_texts, is_non_empty\n\ncleaned, non_empty = process_texts_vect(emails['message'].tolist())\nemails['cleaned_message'] = cleaned\nemails['is_non_empty'] = non_empty\n\nnon_empty_count = emails['is_non_empty'].sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:32:26.573674Z","iopub.execute_input":"2025-09-23T19:32:26.574130Z","iopub.status.idle":"2025-09-23T19:40:35.460901Z","shell.execute_reply.started":"2025-09-23T19:32:26.574104Z","shell.execute_reply":"2025-09-23T19:40:35.460322Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(non_empty_count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:40:35.462027Z","iopub.execute_input":"2025-09-23T19:40:35.462244Z","iopub.status.idle":"2025-09-23T19:40:35.466219Z","shell.execute_reply.started":"2025-09-23T19:40:35.462219Z","shell.execute_reply":"2025-09-23T19:40:35.465647Z"}},"outputs":[{"name":"stdout","text":"517401\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"emails['cleaned_message'][3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:40:35.466826Z","iopub.execute_input":"2025-09-23T19:40:35.467062Z","iopub.status.idle":"2025-09-23T19:40:35.480125Z","shell.execute_reply.started":"2025-09-23T19:40:35.467037Z","shell.execute_reply":"2025-09-23T19:40:35.479540Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'\\nRandy,\\n\\n Can you send me a schedule of the salary and level of everyone in the \\nscheduling group.  Plus your thoughts on any changes that need to be made.  \\n(Patti S for example)\\n\\nPhillip'"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Для следующего задания вам нужно будет токенизировать текст. Для этого просто разбейте его по словам. Очевидно, итоговый результат для финального пользователя будет лучше, если ваша система также будет предлагать уместную пунктуацию. Но если вы заметите, что из-за этого падает качество самого текса, то можете удалить все небуквенные символы на этапе токенизации.","metadata":{}},{"cell_type":"code","source":"import string\nimport re\n\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]|\\d+', '', text)\n    return text\n\nemails['cleaned_message'] = emails['cleaned_message'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:41:31.005013Z","iopub.execute_input":"2025-09-23T19:41:31.005259Z","iopub.status.idle":"2025-09-23T19:42:05.337756Z","shell.execute_reply.started":"2025-09-23T19:41:31.005236Z","shell.execute_reply":"2025-09-23T19:42:05.337181Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"emails['cleaned_message'] = emails['cleaned_message'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:42:05.338956Z","iopub.execute_input":"2025-09-23T19:42:05.339197Z","iopub.status.idle":"2025-09-23T19:42:39.587568Z","shell.execute_reply.started":"2025-09-23T19:42:05.339171Z","shell.execute_reply":"2025-09-23T19:42:39.586966Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"emails['cleaned_message']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:47:15.614244Z","iopub.execute_input":"2025-09-23T19:47:15.614932Z","iopub.status.idle":"2025-09-23T19:47:15.621072Z","shell.execute_reply.started":"2025-09-23T19:47:15.614907Z","shell.execute_reply":"2025-09-23T19:47:15.620416Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0                               \\nHere is our forecast\\n\\n \n1         \\nTraveling to have a business meeting takes t...\n2                              \\ntest successful  way to go\n3         \\nRandy\\n\\n Can you send me a schedule of the ...\n4                            \\nLets shoot for Tuesday at   \n                                ...                        \n517396    \\nThis is a trade with OILSPECHEDGENG John Lav...\n517397    \\nSome of my position is with the Alberta Term...\n517398    \\n\\n\\n Original Message\\nFrom \\tDoucet Dawn  \\...\n517399    \\nAnalyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\...\n517400    \\ni think the YMCA has a class that is for peo...\nName: cleaned_message, Length: 517401, dtype: object"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"emails['tokenized_message'] = emails['cleaned_message'].str.findall(r'\\w+')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:47:19.139227Z","iopub.execute_input":"2025-09-23T19:47:19.139968Z","iopub.status.idle":"2025-09-23T19:48:01.317751Z","shell.execute_reply.started":"2025-09-23T19:47:19.139942Z","shell.execute_reply":"2025-09-23T19:48:01.317154Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"emails['tokenized_message']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:48:01.318799Z","iopub.execute_input":"2025-09-23T19:48:01.319030Z","iopub.status.idle":"2025-09-23T19:48:01.326592Z","shell.execute_reply.started":"2025-09-23T19:48:01.319006Z","shell.execute_reply":"2025-09-23T19:48:01.325934Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0                                 [Here, is, our, forecast]\n1         [Traveling, to, have, a, business, meeting, ta...\n2                           [test, successful, way, to, go]\n3         [Randy, Can, you, send, me, a, schedule, of, t...\n4                           [Lets, shoot, for, Tuesday, at]\n                                ...                        \n517396    [This, is, a, trade, with, OILSPECHEDGENG, Joh...\n517397    [Some, of, my, position, is, with, the, Albert...\n517398    [Original, Message, From, Doucet, Dawn, Sent, ...\n517399    [Analyst, Rank, Stephane, Brodeur, Chad, Clark...\n517400    [i, think, the, YMCA, has, a, class, that, is,...\nName: tokenized_message, Length: 517401, dtype: object"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Общая схема решения\n\nМы хотим сделать систему, которая будет ускорять набор текста, советуя подходящие продолжения. Для подсказки следующего слова мы будем использовать n-граммную модель. Так как n-граммная модель работает с целыми словами, а советы мы хотим давать в риал-тайме даже когда слово еще не дописано, сперва надо научиться дополнять слово до целого.","metadata":{}},{"cell_type":"markdown","source":"## Дополнение слова\n\nВ этой части вам предстоит реализовать метод дополнения слова до целого по его началу (префиксу). Для этого сперва необходимо научиться находить все слова, имеющие определенный префикс. Мы будем вызывать функцию поиска подходящих слов после каждой напечатанной пользователем буквы. Поэтому нам очень важно, чтобы поиск работал как можно быстрее. Простой перебор всех слов занимает $O(|V| \\cdot n)$ времени, где $|V|$ – размер словаря, а $n$ – длина префикса. Мы же напишем [префиксное дерево](https://ru.wikipedia.org/wiki/Префиксное_дерево), которое позволяет искать слова не больше чем за $O(n + mk)$, где $m$ - число подходящих слов, а $k$ – длина суффикса.","metadata":{}},{"cell_type":"markdown","source":"__Задание 2 (2 балла).__ Допишите префиксное дерево для поиска слов по префиксу.","metadata":{}},{"cell_type":"code","source":"from typing import List\n\nclass PrefixTreeNode:\n    def __init__(self):\n        self.children: dict[str, PrefixTreeNode] = {}\n        self.is_end_of_word = False\n\nclass PrefixTree:\n    def __init__(self, vocabulary: List[str]):\n        \"\"\"\n        vocabulary: список всех уникальных токенов в корпусе\n        \"\"\"\n        self.root = PrefixTreeNode()\n        for word in vocabulary:\n            current = self.root\n            for symbol in word:\n                if symbol not in current.children:\n                    current.children[symbol] = PrefixTreeNode()\n                current = current.children[symbol]   \n            current.is_end_of_word = True\n        # your code here\n\n    def search_prefix(self, prefix) -> List[str]:\n        \"\"\"\n        Возвращает все слова, начинающиеся на prefix\n        prefix: str – префикс слова\n        \"\"\"\n        words = []\n        current = self.root\n        for char in prefix:\n            if char not in current.children:\n                return words\n            current = current.children[char]\n\n        def _dfs(current, path):\n            if current.is_end_of_word:\n                words.append(\"\".join(path))\n                \n            for c, children_node in current.children.items():\n                _dfs(children_node, path + [c])\n                \n        _dfs(current, list(prefix))\n\n        return words\n                \n\n        # your code here","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:49:16.713412Z","iopub.execute_input":"2025-09-23T19:49:16.713645Z","iopub.status.idle":"2025-09-23T19:49:16.720716Z","shell.execute_reply.started":"2025-09-23T19:49:16.713631Z","shell.execute_reply":"2025-09-23T19:49:16.720048Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"vocabulary = ['aa', 'aaa', 'abb', 'bba', 'bbb', 'bcd']\nprefix_tree = PrefixTree(vocabulary)\n\nassert set(prefix_tree.search_prefix('a')) == set(['aa', 'aaa', 'abb'])\nassert set(prefix_tree.search_prefix('bb')) == set(['bba', 'bbb'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T19:49:20.374184Z","iopub.execute_input":"2025-09-23T19:49:20.374764Z","iopub.status.idle":"2025-09-23T19:49:20.378538Z","shell.execute_reply.started":"2025-09-23T19:49:20.374739Z","shell.execute_reply":"2025-09-23T19:49:20.377905Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"Теперь, когда у нас есть способ быстро находить все слова с определенным префиксом, нам нужно их упорядочить по вероятности, чтобы выбирать лучшее. Будем оценивать вероятность слова по частоте его __встречаемости в корпусе__.\n\n__Задание 3 (2 балла).__ Допишите класс `WordCompletor`, который формирует словарь и префиксное дерево, а так же умеет находить все возможные продолжения слова вместе с их вероятностями. В этом классе вы можете при необходимости дополнительно отфильтровать слова, например, удалив все самые редкие. Постарайтесь максимально оптимизировать ваш код.","metadata":{}},{"cell_type":"code","source":"from itertools import chain\nfrom collections import Counter\nfrom typing import List\n\nclass WordCompletor:\n    def __init__(self, corpus):\n        \"\"\"\n        corpus: list – корпус текстов\n        \"\"\"\n        # your code here\n        vocabulary = list(chain.from_iterable(corpus)) #из списка списком делаем один список\n        all_words = len(vocabulary)\n        count = Counter(vocabulary) #считаем количество попаданий для каждого слова в тексте\n        self.words_probs = {key: value / all_words for key, value in count.items()} #считаем вероятности\n        u_words = list(set(vocabulary)) #убираем повторяющиеся слова\n        self.prefix_tree = PrefixTree(u_words)\n\n    def get_words_and_probs(self, prefix: str) -> (List[str], List[float]):\n        \"\"\"\n        Возвращает список слов, начинающихся на prefix,\n        с их вероятностями (нормировать ничего не нужно)\n        \"\"\"\n        words, probs = [], []\n        # your code here\n        words = self.prefix_tree.search_prefix(prefix)\n        for word in words:\n            if word in self.words_probs:\n                probs.append(self.words_probs[word])\n        return words, probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:44:43.153839Z","iopub.execute_input":"2025-09-23T22:44:43.154375Z","iopub.status.idle":"2025-09-23T22:44:43.160457Z","shell.execute_reply.started":"2025-09-23T22:44:43.154353Z","shell.execute_reply":"2025-09-23T22:44:43.159830Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"dummy_corpus = [\n    [\"aa\", \"ab\"],\n    [\"aaa\", \"abab\"],\n    [\"abb\", \"aa\", \"ab\", \"bba\", \"bbb\", \"bcd\"],\n]\n\nword_completor = WordCompletor(dummy_corpus)\nwords, probs = word_completor.get_words_and_probs('a')\nwords_probs = list(zip(words, probs))\nassert set(words_probs) == {('aa', 0.2), ('ab', 0.2), ('aaa', 0.1), ('abab', 0.1), ('abb', 0.1)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:44:46.995656Z","iopub.execute_input":"2025-09-23T22:44:46.995913Z","iopub.status.idle":"2025-09-23T22:44:47.001093Z","shell.execute_reply.started":"2025-09-23T22:44:46.995891Z","shell.execute_reply":"2025-09-23T22:44:47.000237Z"}},"outputs":[],"execution_count":100},{"cell_type":"markdown","source":"## Предсказание следующих слов\n\nТеперь, когда мы умеем дописывать слово за пользователем, мы можем пойти дальше и предожить ему следующее слово (или несколько) с учетом дописанного. Для этого мы воспользуемся n-граммной моделью.\n\nНапомним, что вероятность последовательности для такой модели записывается по формуле\n$$\nP(w_1, \\dots, w_T) = \\prod_{i=1}^T P(w_i \\mid w_{i-1}, \\dots, w_{i-n}).\n$$\n\n$P(w_i \\mid w_{i-1}, \\dots, w_{i-n})$ оценивается по частоте встречаемости n-граммы.   \n\n__Задание 4 (2 балла).__ Напишите класс для n-граммной модели. Никакого сглаживания добавлять не надо, мы же не хотим, чтобы модель советовала случайные слова (хоть и очень редко).","metadata":{}},{"cell_type":"code","source":"import nltk\n\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T17:40:36.327771Z","iopub.execute_input":"2025-09-24T17:40:36.328006Z","iopub.status.idle":"2025-09-24T17:40:37.864452Z","shell.execute_reply.started":"2025-09-24T17:40:36.327983Z","shell.execute_reply":"2025-09-24T17:40:37.863730Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from itertools import chain\nfrom nltk.util import ngrams\n\ncorpus = [\n    ['aa', 'aa', 'aa', 'aa', 'ab'],\n    ['aaa', 'abab'],\n    ['abb', 'aa', 'ab', 'bba', 'bbb', 'bcd']\n]\n\nlist(chain.from_iterable(ngrams(seq, 2+1) for seq in corpus)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T17:41:30.399563Z","iopub.execute_input":"2025-09-24T17:41:30.400254Z","iopub.status.idle":"2025-09-24T17:41:30.405764Z","shell.execute_reply.started":"2025-09-24T17:41:30.400227Z","shell.execute_reply":"2025-09-24T17:41:30.405179Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[('aa', 'aa', 'aa'),\n ('aa', 'aa', 'aa'),\n ('aa', 'aa', 'ab'),\n ('abb', 'aa', 'ab'),\n ('aa', 'ab', 'bba'),\n ('ab', 'bba', 'bbb'),\n ('bba', 'bbb', 'bcd')]"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from nltk.util import ngrams\nfrom collections import Counter\nfrom itertools import chain\nfrom fractions import Fraction\n\n\nclass NGramLanguageModel:\n    def __init__(self, corpus, n):\n\n        self.ngrams = list(chain.from_iterable(ngrams(seq, n+1) for seq in corpus))  \n        self.n = n\n        # your code here\n\n    def get_next_words_and_probs(self, prefix: list) -> (List[str], List[float]):\n        \"\"\"\n        Возвращает список слов, которые могут идти после prefix,\n        а так же список вероятностей этих слов\n        \"\"\"\n        next_words, probs = [], []\n\n        endings = []\n\n        for ngram in self.ngrams:\n            if \" \".join(ngram[:self.n]) == \" \". join(prefix):\n                endings.append(ngram[self.n])\n\n        probs_dict = Counter(endings)\n\n        all_endings = len(endings)\n\n        for key, value in probs_dict.items():\n            next_words.append(key)\n            probs.append(value / all_endings)\n        # your code here\n\n        return next_words, probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T23:01:48.723103Z","iopub.execute_input":"2025-09-23T23:01:48.723654Z","iopub.status.idle":"2025-09-23T23:01:48.729541Z","shell.execute_reply.started":"2025-09-23T23:01:48.723620Z","shell.execute_reply":"2025-09-23T23:01:48.728788Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"dummy_corpus = [\n    ['aa', 'aa', 'aa', 'aa', 'ab'],\n    ['aaa', 'abab'],\n    ['abb', 'aa', 'ab', 'bba', 'bbb', 'bcd']\n]\n\nn_gram_model = NGramLanguageModel(corpus=dummy_corpus, n=2)\n\nnext_words, probs = n_gram_model.get_next_words_and_probs(['aa', 'aa'])\nwords_probs = list(zip(next_words, probs))\n\nassert set(words_probs) == {('aa', 2/3), ('ab', 1/3)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T23:01:51.691908Z","iopub.execute_input":"2025-09-23T23:01:51.692141Z","iopub.status.idle":"2025-09-23T23:01:51.696737Z","shell.execute_reply.started":"2025-09-23T23:01:51.692126Z","shell.execute_reply":"2025-09-23T23:01:51.695841Z"}},"outputs":[],"execution_count":112},{"cell_type":"markdown","source":"Отлично, мы теперь можем объединить два метода в автоматический дописыватель текстов: первый будет дополнять слово, а второй – предлагать продолжения. Хочется, чтобы предлагался список возможных продолжений, из который пользователь сможет выбрать наиболее подходящее. Самое сложное тут – аккуратно выбирать, что показывать, а что нет.   \n\n__Задание 5 (2 балла).__ В качестве первого подхода к снаряду реализуйте метод, возвращающий всегда самое вероятное продолжение жадным способом. После этого можно добавить опцию генерации нескольких вариантов продолжений, что сделает метод гораздо лучше.","metadata":{}},{"cell_type":"code","source":"from typing import Union\n\nclass TextSuggestion:\n    def __init__(self, word_completor, n_gram_model):\n        self.word_completor = word_completor\n        self.n_gram_model = n_gram_model\n\n    def suggest_text(self, text: Union[str, list], n_words=3, n_texts=1) -> list[list[str]]:\n        \"\"\"\n        Возвращает возможные варианты продолжения текста (по умолчанию только один)\n        \n        text: строка или список слов – написанный пользователем текст\n        n_words: число слов, которые дописывает n-граммная модель\n        n_texts: число возвращаемых продолжений (пока что только одно)\n        \n        return: list[list[srt]] – список из n_texts списков слов, по 1 + n_words слов в каждом\n        Первое слово – это то, которое WordCompletor дополнил до целого.\n        \"\"\"\n\n        suggestions = []\n\n        for _ in range(n_texts):\n            current_word = text[-1]\n            context = text[:-1] if len(text) > 1 else []\n            words, _ = self.word_completor.get_words_and_probs(current_word)\n            \n            recommended_word = words[0]\n            current_suggestion = [recommended_word]\n            \n            current_context = context + [recommended_word]\n            \n            for i in range(n_words):\n                \n                prefix = current_context[-self.n_gram_model.n:] if len(current_context) >= self.n_gram_model.n else current_context\n                next_words, probs = self.n_gram_model.get_next_words_and_probs(prefix)\n                most_probable_word = next_words[0]\n                \n                current_suggestion.append(most_probable_word)\n                current_context.append(most_probable_word)\n                \n            suggestions.append(current_suggestion)\n\n        # your code here\n\n        return suggestions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T23:02:00.968176Z","iopub.execute_input":"2025-09-23T23:02:00.968677Z","iopub.status.idle":"2025-09-23T23:02:00.975047Z","shell.execute_reply.started":"2025-09-23T23:02:00.968652Z","shell.execute_reply":"2025-09-23T23:02:00.974347Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"dummy_corpus = [\n    ['aa', 'aa', 'aa', 'aa', 'ab'],\n    ['aaa', 'abab'],\n    ['abb', 'aa', 'ab', 'bba', 'bbb', 'bcd']\n]\n\nword_completor = WordCompletor(dummy_corpus)\nn_gram_model = NGramLanguageModel(corpus=dummy_corpus, n=2)\ntext_suggestion = TextSuggestion(word_completor, n_gram_model)\n\nassert text_suggestion.suggest_text(['aa', 'aa'], n_words=3, n_texts=1) == [['aa', 'aa', 'aa', 'aa']]\nassert text_suggestion.suggest_text(['abb', 'aa', 'ab'], n_words=2, n_texts=1) == [['ab', 'bba', 'bbb']]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-24T09:34:15.438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_suggestion = TextSuggestion(word_completor, n_gram_model)","metadata":{},"outputs":[],"execution_count":450},{"cell_type":"markdown","source":"## Бонусная часть: Добавляем UI","metadata":{}},{"cell_type":"markdown","source":"Запускать ячейки в юпитере – это хорошо, но будет лучше, если вашим решением действительно можно будет пользоваться. Для этого вам предлагается добавить полноценных User Interface. Мы рекомендуем использовать для этого [reflex](https://github.com/reflex-dev/reflex). Это Python библиотека для создания web-интерфейсом с очень богатым функционалом.\n\nВаша задача – сделать поле для текстового ввода, при наборе текста в котором будут появляться подсказки в реальном времени. Продумайте, как пользователь будет выбирать подсказки, сколько продолжений рекомендавать и так далее. В общем, должно получиться красиво и удобно. В этой части вы можете модифицировать все классы по своему усмотрению и добавлять любые эвристики. Если нужно, то дополнительно обрабатывать текст и вообще делать все, что считаете нужным. \n\nЗа это задание можно получить до __5-ти бонусных баллов__ в зависимости о того, насколько хорошо и удобно у вас получилось. При сдаче задания прикрепите небольшой __отчет__ (полстраницы) с описанием вашей системы, а также __видео__ (1-2 минуты) с демонстрацией работы интерфейса.\n\nМы настоятельно рекомендуем вам оформить код в проект, а не писать в ноутбуке. Но если вам очень хочется писать тут, то хотя бы не меняйте код в предыдущих заданиях, чтобы его можно было нормально оценивать.","metadata":{}}]}